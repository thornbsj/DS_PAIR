{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0780568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,DataCollatorForLanguageModeling,TrainingArguments,Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff41b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"augumentation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f2ac87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7adeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.select([i for i,x in enumerate(data[\"description\"]) if len(x)>=50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ea8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bigscience/bloomz-1b7\"\n",
    "tokenizer_name = \"bigscience/bloomz-1b7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0292c35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebb6b053705405aa6ffaf8f77d893ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,trust_remote_code=True,padding='max_length')\n",
    "\n",
    "def preprocess(examples):\n",
    "    if tokenizer.eos_token is not None:\n",
    "        contents = [e + tokenizer.eos_token for e in examples[\"description\"]]\n",
    "    else:\n",
    "        contents = examples[\"description\"]\n",
    "    return tokenizer(contents,max_length = 200)\n",
    "\n",
    "tokenized_ds = ds.map(preprocess,batched=True,remove_columns = ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a78d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name,trust_remote_code=True, low_cpu_mem_usage=True, \n",
    "                                             torch_dtype=torch.half, device_map=\"auto\", load_in_4bit=True, bnb_4bit_compute_dtype=torch.half,\n",
    "                                             bnb_4bit_quant_type=\"nf4\", bnb_4bit_use_double_quant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e76afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7358a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.word_embeddings.weight\n",
      "transformer.word_embeddings_layernorm.weight\n",
      "transformer.word_embeddings_layernorm.bias\n",
      "transformer.h.0.input_layernorm.weight\n",
      "transformer.h.0.input_layernorm.bias\n",
      "transformer.h.0.self_attention.query_key_value.weight\n",
      "transformer.h.0.self_attention.query_key_value.bias\n",
      "transformer.h.0.self_attention.dense.weight\n",
      "transformer.h.0.self_attention.dense.bias\n",
      "transformer.h.0.post_attention_layernorm.weight\n",
      "transformer.h.0.post_attention_layernorm.bias\n",
      "transformer.h.0.mlp.dense_h_to_4h.weight\n",
      "transformer.h.0.mlp.dense_h_to_4h.bias\n",
      "transformer.h.0.mlp.dense_4h_to_h.weight\n",
      "transformer.h.0.mlp.dense_4h_to_h.bias\n",
      "transformer.h.1.input_layernorm.weight\n",
      "transformer.h.1.input_layernorm.bias\n",
      "transformer.h.1.self_attention.query_key_value.weight\n",
      "transformer.h.1.self_attention.query_key_value.bias\n",
      "transformer.h.1.self_attention.dense.weight\n",
      "transformer.h.1.self_attention.dense.bias\n",
      "transformer.h.1.post_attention_layernorm.weight\n",
      "transformer.h.1.post_attention_layernorm.bias\n",
      "transformer.h.1.mlp.dense_h_to_4h.weight\n",
      "transformer.h.1.mlp.dense_h_to_4h.bias\n",
      "transformer.h.1.mlp.dense_4h_to_h.weight\n",
      "transformer.h.1.mlp.dense_4h_to_h.bias\n",
      "transformer.h.2.input_layernorm.weight\n",
      "transformer.h.2.input_layernorm.bias\n",
      "transformer.h.2.self_attention.query_key_value.weight\n",
      "transformer.h.2.self_attention.query_key_value.bias\n",
      "transformer.h.2.self_attention.dense.weight\n",
      "transformer.h.2.self_attention.dense.bias\n",
      "transformer.h.2.post_attention_layernorm.weight\n",
      "transformer.h.2.post_attention_layernorm.bias\n",
      "transformer.h.2.mlp.dense_h_to_4h.weight\n",
      "transformer.h.2.mlp.dense_h_to_4h.bias\n",
      "transformer.h.2.mlp.dense_4h_to_h.weight\n",
      "transformer.h.2.mlp.dense_4h_to_h.bias\n",
      "transformer.h.3.input_layernorm.weight\n",
      "transformer.h.3.input_layernorm.bias\n",
      "transformer.h.3.self_attention.query_key_value.weight\n",
      "transformer.h.3.self_attention.query_key_value.bias\n",
      "transformer.h.3.self_attention.dense.weight\n",
      "transformer.h.3.self_attention.dense.bias\n",
      "transformer.h.3.post_attention_layernorm.weight\n",
      "transformer.h.3.post_attention_layernorm.bias\n",
      "transformer.h.3.mlp.dense_h_to_4h.weight\n",
      "transformer.h.3.mlp.dense_h_to_4h.bias\n",
      "transformer.h.3.mlp.dense_4h_to_h.weight\n",
      "transformer.h.3.mlp.dense_4h_to_h.bias\n",
      "transformer.h.4.input_layernorm.weight\n",
      "transformer.h.4.input_layernorm.bias\n",
      "transformer.h.4.self_attention.query_key_value.weight\n",
      "transformer.h.4.self_attention.query_key_value.bias\n",
      "transformer.h.4.self_attention.dense.weight\n",
      "transformer.h.4.self_attention.dense.bias\n",
      "transformer.h.4.post_attention_layernorm.weight\n",
      "transformer.h.4.post_attention_layernorm.bias\n",
      "transformer.h.4.mlp.dense_h_to_4h.weight\n",
      "transformer.h.4.mlp.dense_h_to_4h.bias\n",
      "transformer.h.4.mlp.dense_4h_to_h.weight\n",
      "transformer.h.4.mlp.dense_4h_to_h.bias\n",
      "transformer.h.5.input_layernorm.weight\n",
      "transformer.h.5.input_layernorm.bias\n",
      "transformer.h.5.self_attention.query_key_value.weight\n",
      "transformer.h.5.self_attention.query_key_value.bias\n",
      "transformer.h.5.self_attention.dense.weight\n",
      "transformer.h.5.self_attention.dense.bias\n",
      "transformer.h.5.post_attention_layernorm.weight\n",
      "transformer.h.5.post_attention_layernorm.bias\n",
      "transformer.h.5.mlp.dense_h_to_4h.weight\n",
      "transformer.h.5.mlp.dense_h_to_4h.bias\n",
      "transformer.h.5.mlp.dense_4h_to_h.weight\n",
      "transformer.h.5.mlp.dense_4h_to_h.bias\n",
      "transformer.h.6.input_layernorm.weight\n",
      "transformer.h.6.input_layernorm.bias\n",
      "transformer.h.6.self_attention.query_key_value.weight\n",
      "transformer.h.6.self_attention.query_key_value.bias\n",
      "transformer.h.6.self_attention.dense.weight\n",
      "transformer.h.6.self_attention.dense.bias\n",
      "transformer.h.6.post_attention_layernorm.weight\n",
      "transformer.h.6.post_attention_layernorm.bias\n",
      "transformer.h.6.mlp.dense_h_to_4h.weight\n",
      "transformer.h.6.mlp.dense_h_to_4h.bias\n",
      "transformer.h.6.mlp.dense_4h_to_h.weight\n",
      "transformer.h.6.mlp.dense_4h_to_h.bias\n",
      "transformer.h.7.input_layernorm.weight\n",
      "transformer.h.7.input_layernorm.bias\n",
      "transformer.h.7.self_attention.query_key_value.weight\n",
      "transformer.h.7.self_attention.query_key_value.bias\n",
      "transformer.h.7.self_attention.dense.weight\n",
      "transformer.h.7.self_attention.dense.bias\n",
      "transformer.h.7.post_attention_layernorm.weight\n",
      "transformer.h.7.post_attention_layernorm.bias\n",
      "transformer.h.7.mlp.dense_h_to_4h.weight\n",
      "transformer.h.7.mlp.dense_h_to_4h.bias\n",
      "transformer.h.7.mlp.dense_4h_to_h.weight\n",
      "transformer.h.7.mlp.dense_4h_to_h.bias\n",
      "transformer.h.8.input_layernorm.weight\n",
      "transformer.h.8.input_layernorm.bias\n",
      "transformer.h.8.self_attention.query_key_value.weight\n",
      "transformer.h.8.self_attention.query_key_value.bias\n",
      "transformer.h.8.self_attention.dense.weight\n",
      "transformer.h.8.self_attention.dense.bias\n",
      "transformer.h.8.post_attention_layernorm.weight\n",
      "transformer.h.8.post_attention_layernorm.bias\n",
      "transformer.h.8.mlp.dense_h_to_4h.weight\n",
      "transformer.h.8.mlp.dense_h_to_4h.bias\n",
      "transformer.h.8.mlp.dense_4h_to_h.weight\n",
      "transformer.h.8.mlp.dense_4h_to_h.bias\n",
      "transformer.h.9.input_layernorm.weight\n",
      "transformer.h.9.input_layernorm.bias\n",
      "transformer.h.9.self_attention.query_key_value.weight\n",
      "transformer.h.9.self_attention.query_key_value.bias\n",
      "transformer.h.9.self_attention.dense.weight\n",
      "transformer.h.9.self_attention.dense.bias\n",
      "transformer.h.9.post_attention_layernorm.weight\n",
      "transformer.h.9.post_attention_layernorm.bias\n",
      "transformer.h.9.mlp.dense_h_to_4h.weight\n",
      "transformer.h.9.mlp.dense_h_to_4h.bias\n",
      "transformer.h.9.mlp.dense_4h_to_h.weight\n",
      "transformer.h.9.mlp.dense_4h_to_h.bias\n",
      "transformer.h.10.input_layernorm.weight\n",
      "transformer.h.10.input_layernorm.bias\n",
      "transformer.h.10.self_attention.query_key_value.weight\n",
      "transformer.h.10.self_attention.query_key_value.bias\n",
      "transformer.h.10.self_attention.dense.weight\n",
      "transformer.h.10.self_attention.dense.bias\n",
      "transformer.h.10.post_attention_layernorm.weight\n",
      "transformer.h.10.post_attention_layernorm.bias\n",
      "transformer.h.10.mlp.dense_h_to_4h.weight\n",
      "transformer.h.10.mlp.dense_h_to_4h.bias\n",
      "transformer.h.10.mlp.dense_4h_to_h.weight\n",
      "transformer.h.10.mlp.dense_4h_to_h.bias\n",
      "transformer.h.11.input_layernorm.weight\n",
      "transformer.h.11.input_layernorm.bias\n",
      "transformer.h.11.self_attention.query_key_value.weight\n",
      "transformer.h.11.self_attention.query_key_value.bias\n",
      "transformer.h.11.self_attention.dense.weight\n",
      "transformer.h.11.self_attention.dense.bias\n",
      "transformer.h.11.post_attention_layernorm.weight\n",
      "transformer.h.11.post_attention_layernorm.bias\n",
      "transformer.h.11.mlp.dense_h_to_4h.weight\n",
      "transformer.h.11.mlp.dense_h_to_4h.bias\n",
      "transformer.h.11.mlp.dense_4h_to_h.weight\n",
      "transformer.h.11.mlp.dense_4h_to_h.bias\n",
      "transformer.h.12.input_layernorm.weight\n",
      "transformer.h.12.input_layernorm.bias\n",
      "transformer.h.12.self_attention.query_key_value.weight\n",
      "transformer.h.12.self_attention.query_key_value.bias\n",
      "transformer.h.12.self_attention.dense.weight\n",
      "transformer.h.12.self_attention.dense.bias\n",
      "transformer.h.12.post_attention_layernorm.weight\n",
      "transformer.h.12.post_attention_layernorm.bias\n",
      "transformer.h.12.mlp.dense_h_to_4h.weight\n",
      "transformer.h.12.mlp.dense_h_to_4h.bias\n",
      "transformer.h.12.mlp.dense_4h_to_h.weight\n",
      "transformer.h.12.mlp.dense_4h_to_h.bias\n",
      "transformer.h.13.input_layernorm.weight\n",
      "transformer.h.13.input_layernorm.bias\n",
      "transformer.h.13.self_attention.query_key_value.weight\n",
      "transformer.h.13.self_attention.query_key_value.bias\n",
      "transformer.h.13.self_attention.dense.weight\n",
      "transformer.h.13.self_attention.dense.bias\n",
      "transformer.h.13.post_attention_layernorm.weight\n",
      "transformer.h.13.post_attention_layernorm.bias\n",
      "transformer.h.13.mlp.dense_h_to_4h.weight\n",
      "transformer.h.13.mlp.dense_h_to_4h.bias\n",
      "transformer.h.13.mlp.dense_4h_to_h.weight\n",
      "transformer.h.13.mlp.dense_4h_to_h.bias\n",
      "transformer.h.14.input_layernorm.weight\n",
      "transformer.h.14.input_layernorm.bias\n",
      "transformer.h.14.self_attention.query_key_value.weight\n",
      "transformer.h.14.self_attention.query_key_value.bias\n",
      "transformer.h.14.self_attention.dense.weight\n",
      "transformer.h.14.self_attention.dense.bias\n",
      "transformer.h.14.post_attention_layernorm.weight\n",
      "transformer.h.14.post_attention_layernorm.bias\n",
      "transformer.h.14.mlp.dense_h_to_4h.weight\n",
      "transformer.h.14.mlp.dense_h_to_4h.bias\n",
      "transformer.h.14.mlp.dense_4h_to_h.weight\n",
      "transformer.h.14.mlp.dense_4h_to_h.bias\n",
      "transformer.h.15.input_layernorm.weight\n",
      "transformer.h.15.input_layernorm.bias\n",
      "transformer.h.15.self_attention.query_key_value.weight\n",
      "transformer.h.15.self_attention.query_key_value.bias\n",
      "transformer.h.15.self_attention.dense.weight\n",
      "transformer.h.15.self_attention.dense.bias\n",
      "transformer.h.15.post_attention_layernorm.weight\n",
      "transformer.h.15.post_attention_layernorm.bias\n",
      "transformer.h.15.mlp.dense_h_to_4h.weight\n",
      "transformer.h.15.mlp.dense_h_to_4h.bias\n",
      "transformer.h.15.mlp.dense_4h_to_h.weight\n",
      "transformer.h.15.mlp.dense_4h_to_h.bias\n",
      "transformer.h.16.input_layernorm.weight\n",
      "transformer.h.16.input_layernorm.bias\n",
      "transformer.h.16.self_attention.query_key_value.weight\n",
      "transformer.h.16.self_attention.query_key_value.bias\n",
      "transformer.h.16.self_attention.dense.weight\n",
      "transformer.h.16.self_attention.dense.bias\n",
      "transformer.h.16.post_attention_layernorm.weight\n",
      "transformer.h.16.post_attention_layernorm.bias\n",
      "transformer.h.16.mlp.dense_h_to_4h.weight\n",
      "transformer.h.16.mlp.dense_h_to_4h.bias\n",
      "transformer.h.16.mlp.dense_4h_to_h.weight\n",
      "transformer.h.16.mlp.dense_4h_to_h.bias\n",
      "transformer.h.17.input_layernorm.weight\n",
      "transformer.h.17.input_layernorm.bias\n",
      "transformer.h.17.self_attention.query_key_value.weight\n",
      "transformer.h.17.self_attention.query_key_value.bias\n",
      "transformer.h.17.self_attention.dense.weight\n",
      "transformer.h.17.self_attention.dense.bias\n",
      "transformer.h.17.post_attention_layernorm.weight\n",
      "transformer.h.17.post_attention_layernorm.bias\n",
      "transformer.h.17.mlp.dense_h_to_4h.weight\n",
      "transformer.h.17.mlp.dense_h_to_4h.bias\n",
      "transformer.h.17.mlp.dense_4h_to_h.weight\n",
      "transformer.h.17.mlp.dense_4h_to_h.bias\n",
      "transformer.h.18.input_layernorm.weight\n",
      "transformer.h.18.input_layernorm.bias\n",
      "transformer.h.18.self_attention.query_key_value.weight\n",
      "transformer.h.18.self_attention.query_key_value.bias\n",
      "transformer.h.18.self_attention.dense.weight\n",
      "transformer.h.18.self_attention.dense.bias\n",
      "transformer.h.18.post_attention_layernorm.weight\n",
      "transformer.h.18.post_attention_layernorm.bias\n",
      "transformer.h.18.mlp.dense_h_to_4h.weight\n",
      "transformer.h.18.mlp.dense_h_to_4h.bias\n",
      "transformer.h.18.mlp.dense_4h_to_h.weight\n",
      "transformer.h.18.mlp.dense_4h_to_h.bias\n",
      "transformer.h.19.input_layernorm.weight\n",
      "transformer.h.19.input_layernorm.bias\n",
      "transformer.h.19.self_attention.query_key_value.weight\n",
      "transformer.h.19.self_attention.query_key_value.bias\n",
      "transformer.h.19.self_attention.dense.weight\n",
      "transformer.h.19.self_attention.dense.bias\n",
      "transformer.h.19.post_attention_layernorm.weight\n",
      "transformer.h.19.post_attention_layernorm.bias\n",
      "transformer.h.19.mlp.dense_h_to_4h.weight\n",
      "transformer.h.19.mlp.dense_h_to_4h.bias\n",
      "transformer.h.19.mlp.dense_4h_to_h.weight\n",
      "transformer.h.19.mlp.dense_4h_to_h.bias\n",
      "transformer.h.20.input_layernorm.weight\n",
      "transformer.h.20.input_layernorm.bias\n",
      "transformer.h.20.self_attention.query_key_value.weight\n",
      "transformer.h.20.self_attention.query_key_value.bias\n",
      "transformer.h.20.self_attention.dense.weight\n",
      "transformer.h.20.self_attention.dense.bias\n",
      "transformer.h.20.post_attention_layernorm.weight\n",
      "transformer.h.20.post_attention_layernorm.bias\n",
      "transformer.h.20.mlp.dense_h_to_4h.weight\n",
      "transformer.h.20.mlp.dense_h_to_4h.bias\n",
      "transformer.h.20.mlp.dense_4h_to_h.weight\n",
      "transformer.h.20.mlp.dense_4h_to_h.bias\n",
      "transformer.h.21.input_layernorm.weight\n",
      "transformer.h.21.input_layernorm.bias\n",
      "transformer.h.21.self_attention.query_key_value.weight\n",
      "transformer.h.21.self_attention.query_key_value.bias\n",
      "transformer.h.21.self_attention.dense.weight\n",
      "transformer.h.21.self_attention.dense.bias\n",
      "transformer.h.21.post_attention_layernorm.weight\n",
      "transformer.h.21.post_attention_layernorm.bias\n",
      "transformer.h.21.mlp.dense_h_to_4h.weight\n",
      "transformer.h.21.mlp.dense_h_to_4h.bias\n",
      "transformer.h.21.mlp.dense_4h_to_h.weight\n",
      "transformer.h.21.mlp.dense_4h_to_h.bias\n",
      "transformer.h.22.input_layernorm.weight\n",
      "transformer.h.22.input_layernorm.bias\n",
      "transformer.h.22.self_attention.query_key_value.weight\n",
      "transformer.h.22.self_attention.query_key_value.bias\n",
      "transformer.h.22.self_attention.dense.weight\n",
      "transformer.h.22.self_attention.dense.bias\n",
      "transformer.h.22.post_attention_layernorm.weight\n",
      "transformer.h.22.post_attention_layernorm.bias\n",
      "transformer.h.22.mlp.dense_h_to_4h.weight\n",
      "transformer.h.22.mlp.dense_h_to_4h.bias\n",
      "transformer.h.22.mlp.dense_4h_to_h.weight\n",
      "transformer.h.22.mlp.dense_4h_to_h.bias\n",
      "transformer.h.23.input_layernorm.weight\n",
      "transformer.h.23.input_layernorm.bias\n",
      "transformer.h.23.self_attention.query_key_value.weight\n",
      "transformer.h.23.self_attention.query_key_value.bias\n",
      "transformer.h.23.self_attention.dense.weight\n",
      "transformer.h.23.self_attention.dense.bias\n",
      "transformer.h.23.post_attention_layernorm.weight\n",
      "transformer.h.23.post_attention_layernorm.bias\n",
      "transformer.h.23.mlp.dense_h_to_4h.weight\n",
      "transformer.h.23.mlp.dense_h_to_4h.bias\n",
      "transformer.h.23.mlp.dense_4h_to_h.weight\n",
      "transformer.h.23.mlp.dense_4h_to_h.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n"
     ]
    }
   ],
   "source": [
    "for name,value in base_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4674b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad7a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        target_modules=\"transformer.*query_key_value\",\n",
    "        lora_dropout=0.05,\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d13ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,572,864 || all params: 1,723,981,824 || trainable%: 0.09123437254985815\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(base_model,lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2cd1370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = LoraConfig(task_type=TaskType.CAUSAL_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df1065fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.lora_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e67539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"test_for_casual\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    gradient_checkpointing=True,\n",
    "    save_total_limit=1\n",
    "    # learning_rate=5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba8c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    args = train_args,\n",
    "    model = model,\n",
    "    train_dataset = tokenized_ds,\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78da44eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "face934e020442759f878807a5057b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "d:\\Anaconda\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.6726, 'learning_rate': 4.919484702093398e-05, 'epoch': 0.02}\n",
      "{'loss': 5.5004, 'learning_rate': 4.8389694041867956e-05, 'epoch': 0.03}\n",
      "{'loss': 5.4406, 'learning_rate': 4.7584541062801933e-05, 'epoch': 0.05}\n",
      "{'loss': 5.3874, 'learning_rate': 4.677938808373592e-05, 'epoch': 0.06}\n",
      "{'loss': 5.3237, 'learning_rate': 4.597423510466989e-05, 'epoch': 0.08}\n",
      "{'loss': 5.2642, 'learning_rate': 4.5169082125603865e-05, 'epoch': 0.1}\n",
      "{'loss': 5.242, 'learning_rate': 4.436392914653785e-05, 'epoch': 0.11}\n",
      "{'loss': 5.1922, 'learning_rate': 4.355877616747182e-05, 'epoch': 0.13}\n",
      "{'loss': 5.1743, 'learning_rate': 4.27536231884058e-05, 'epoch': 0.14}\n",
      "{'loss': 5.1141, 'learning_rate': 4.194847020933977e-05, 'epoch': 0.16}\n",
      "{'loss': 5.1702, 'learning_rate': 4.1143317230273756e-05, 'epoch': 0.18}\n",
      "{'loss': 5.0816, 'learning_rate': 4.0338164251207733e-05, 'epoch': 0.19}\n",
      "{'loss': 5.1149, 'learning_rate': 3.9533011272141704e-05, 'epoch': 0.21}\n",
      "{'loss': 5.0579, 'learning_rate': 3.872785829307569e-05, 'epoch': 0.23}\n",
      "{'loss': 5.0515, 'learning_rate': 3.7922705314009665e-05, 'epoch': 0.24}\n",
      "{'loss': 5.0461, 'learning_rate': 3.711755233494364e-05, 'epoch': 0.26}\n",
      "{'loss': 5.038, 'learning_rate': 3.631239935587762e-05, 'epoch': 0.27}\n",
      "{'loss': 5.0357, 'learning_rate': 3.5507246376811596e-05, 'epoch': 0.29}\n",
      "{'loss': 5.0089, 'learning_rate': 3.470209339774557e-05, 'epoch': 0.31}\n",
      "{'loss': 4.9869, 'learning_rate': 3.389694041867955e-05, 'epoch': 0.32}\n",
      "{'loss': 5.019, 'learning_rate': 3.3091787439613533e-05, 'epoch': 0.34}\n",
      "{'loss': 5.0512, 'learning_rate': 3.2286634460547504e-05, 'epoch': 0.35}\n",
      "{'loss': 5.0569, 'learning_rate': 3.148148148148148e-05, 'epoch': 0.37}\n",
      "{'loss': 4.9952, 'learning_rate': 3.067632850241546e-05, 'epoch': 0.39}\n",
      "{'loss': 5.0046, 'learning_rate': 2.9871175523349438e-05, 'epoch': 0.4}\n",
      "{'loss': 5.0281, 'learning_rate': 2.9066022544283415e-05, 'epoch': 0.42}\n",
      "{'loss': 4.9847, 'learning_rate': 2.826086956521739e-05, 'epoch': 0.43}\n",
      "{'loss': 4.9391, 'learning_rate': 2.745571658615137e-05, 'epoch': 0.45}\n",
      "{'loss': 4.9722, 'learning_rate': 2.665056360708535e-05, 'epoch': 0.47}\n",
      "{'loss': 4.9817, 'learning_rate': 2.5845410628019323e-05, 'epoch': 0.48}\n",
      "{'loss': 4.9043, 'learning_rate': 2.5040257648953304e-05, 'epoch': 0.5}\n",
      "{'loss': 4.9672, 'learning_rate': 2.423510466988728e-05, 'epoch': 0.51}\n",
      "{'loss': 4.9338, 'learning_rate': 2.3429951690821258e-05, 'epoch': 0.53}\n",
      "{'loss': 4.9578, 'learning_rate': 2.2624798711755235e-05, 'epoch': 0.55}\n",
      "{'loss': 4.9819, 'learning_rate': 2.1819645732689212e-05, 'epoch': 0.56}\n",
      "{'loss': 4.9521, 'learning_rate': 2.101449275362319e-05, 'epoch': 0.58}\n",
      "{'loss': 5.0371, 'learning_rate': 2.020933977455717e-05, 'epoch': 0.6}\n",
      "{'loss': 4.9303, 'learning_rate': 1.9404186795491143e-05, 'epoch': 0.61}\n",
      "{'loss': 4.9584, 'learning_rate': 1.859903381642512e-05, 'epoch': 0.63}\n",
      "{'loss': 4.9678, 'learning_rate': 1.77938808373591e-05, 'epoch': 0.64}\n",
      "{'loss': 4.9766, 'learning_rate': 1.6988727858293077e-05, 'epoch': 0.66}\n",
      "{'loss': 4.9362, 'learning_rate': 1.6183574879227054e-05, 'epoch': 0.68}\n",
      "{'loss': 4.9196, 'learning_rate': 1.537842190016103e-05, 'epoch': 0.69}\n",
      "{'loss': 4.9139, 'learning_rate': 1.457326892109501e-05, 'epoch': 0.71}\n",
      "{'loss': 4.9213, 'learning_rate': 1.3768115942028985e-05, 'epoch': 0.72}\n",
      "{'loss': 4.9517, 'learning_rate': 1.2962962962962962e-05, 'epoch': 0.74}\n",
      "{'loss': 4.9048, 'learning_rate': 1.2157809983896941e-05, 'epoch': 0.76}\n",
      "{'loss': 4.9418, 'learning_rate': 1.1352657004830918e-05, 'epoch': 0.77}\n",
      "{'loss': 4.9379, 'learning_rate': 1.0547504025764895e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test_for_casual\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9603, 'learning_rate': 9.742351046698874e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9515, 'learning_rate': 8.93719806763285e-06, 'epoch': 0.82}\n",
      "{'loss': 4.9885, 'learning_rate': 8.132045088566828e-06, 'epoch': 0.84}\n",
      "{'loss': 4.9012, 'learning_rate': 7.326892109500806e-06, 'epoch': 0.85}\n",
      "{'loss': 4.9433, 'learning_rate': 6.521739130434783e-06, 'epoch': 0.87}\n",
      "{'loss': 4.9495, 'learning_rate': 5.71658615136876e-06, 'epoch': 0.89}\n",
      "{'loss': 4.9086, 'learning_rate': 4.911433172302738e-06, 'epoch': 0.9}\n",
      "{'loss': 4.8918, 'learning_rate': 4.106280193236716e-06, 'epoch': 0.92}\n",
      "{'loss': 4.9231, 'learning_rate': 3.3011272141706927e-06, 'epoch': 0.93}\n",
      "{'loss': 4.9267, 'learning_rate': 2.49597423510467e-06, 'epoch': 0.95}\n",
      "{'loss': 4.9328, 'learning_rate': 1.6908212560386474e-06, 'epoch': 0.97}\n",
      "{'loss': 4.9796, 'learning_rate': 8.856682769726248e-07, 'epoch': 0.98}\n",
      "{'loss': 4.9031, 'learning_rate': 8.051529790660226e-08, 'epoch': 1.0}\n",
      "{'train_runtime': 1741.7308, 'train_samples_per_second': 11.416, 'train_steps_per_second': 0.357, 'train_loss': 5.033601180366848, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=621, training_loss=5.033601180366848, metrics={'train_runtime': 1741.7308, 'train_samples_per_second': 11.416, 'train_steps_per_second': 0.357, 'train_loss': 5.033601180366848, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f3094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model.get_base_model(), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model.get_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51078ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在不死教堂钟楼守护苏醒之钟的法术生物石像鬼的头盔。法力值为零的他们，在失去生命后无法恢复到原本的状态下使用此物会有所伤害 。</s>'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"在不死教堂钟楼守护苏醒之钟的法术生物石像鬼的头盔。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=200,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "01830e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'来历不明的异端咒术，能催发猛毒雾。在施展后可以产生一种巨大的力量和火焰的混合体——火之魔力！这股力量的来源是来自一个古老的传说：一位被诅咒的人用他的灵魂创造了世界；然后他将其释放到空中并变成一团燃烧物而亡了</s>'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"来历不明的异端咒术，能催发猛毒雾。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=200,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68de6dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'来历不明的异端咒术，能够投出带有毒气的火球。据说这把武器是来自一位神秘的魔法师的手中而制成；虽然他并没有留下任何痕迹但他的传说却流传了下来</s>'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"来历不明的异端咒术，能够投出带有毒气的火球。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=200,no_repeat_ngram_size=1,do_sample=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c91aebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'虚铠本身拥有的直剑，剑身有热度，具有火之力。虽然是铁质制成但并不坚硬、不耐用；相反地却非常轻巧且容易移动使用 。</s>'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"虚铠本身拥有的直剑，剑身有热度，具有火之力。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=200,no_repeat_ngram_size=1,do_sample=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3505a912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'神秘咒术师独创的魔法，能够像奇迹那样投掷枪形火焰。据说这把火能将敌人烧成灰烬或燃烧到死为止！</s>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"神秘咒术师独创的魔法，能够像奇迹那样投掷枪形火焰\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=200,no_repeat_ngram_size=1,do_sample=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0e0af7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'将火焰纳入连同自身在内，周遭多人的体内。在火中燃烧的灵魂会变成灰烬而离开身体；当被烧伤时可以恢复生命值和力量等属性（但无法获得任何经验）</s>'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"将火焰纳入连同自身在内，周遭多人的体内。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=200,no_repeat_ngram_size=1,do_sample=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1d00590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'伊扎里斯禁术，将火焰纳入多人的体内让他们暂时提升攻击力，但血量将持续减少。这门魔法是许多古代神灵的遗产之一——他们相信只有拥有火的力量才能达到真正的力量和智慧</s>'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"伊扎里斯禁术，将火焰纳入多人的体内让他们暂时提升攻击力，但血量将持续减少。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=256,do_sample=False,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34f81e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'伊扎里斯咒术中最为可怖的一个。它以一种非常强大的力量，将人变成一个巨大的铁块或石头；然后会像被施了魔法一样地失去所有意识和生命力！</s>'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"伊扎里斯咒术中最为可怖的一个。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=256,do_sample=False,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd741d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'伊扎里斯咒术中最为可怖的一个。将自己的生命化为火焰钻入敌人身体内部。虽然这招威力巨大，但会消耗大量魔力值和灵魂数来恢复力量与精神的平衡度；因此对那些需要使用魔法的人来说是绝对不可取的手段之一</s>'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"伊扎里斯咒术中最为可怖的一个。将自己的生命化为火焰钻入敌人身体内部。\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=256,do_sample=False,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "982f4bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'能散发出持续侵蚀血量的白雾。据说，只要有这种药剂的灵魂就会被腐蚀而亡；因此它是一种非常强大的武器！</s>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"能散发出持续侵蚀血量的白雾\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=256,do_sample=False,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99270787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'无头骑士的长枪。长剑的刀刃是巨大的，但武器本身却非常轻巧、坚固有力；这把武器的威力很大而攻击范围也大到无法想象的程度！</s>'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = tokenizer(\"无头骑士的长枪\",return_tensors=\"pt\").to(base_model.device)\n",
    "tokenizer.decode(model.generate(**ipt,max_length=256,do_sample=False,no_repeat_ngram_size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cb766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
